{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backbone_utils import IntermediateFeatureModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2048])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(model.fc.in_features, 100, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2048])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = IntermediateFeatureModule(model, ['avgpool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR100(\"/mnt/datasets/public/cifar100/\",\n",
    "                    transform=torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize(\n",
    "                            mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]\n",
    "                        )\n",
    "                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_dataset = torch.utils.data.Subset(dataset, np.arange(100))\n",
    "unlabelled_dataset = torch.utils.data.Subset(dataset, np.arange(101, len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_loader = torch.utils.data.DataLoader(labelled_dataset, batch_size=32)\n",
    "unlabelled_loader = torch.utils.data.DataLoader(unlabelled_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding.cuda()\n",
    "labelled_embeddings = []\n",
    "\n",
    "for x, y in labelled_loader:\n",
    "    with torch.no_grad():\n",
    "        x = x.cuda()\n",
    "        labelled_embeddings.append(embedding(x)['avgpool'].squeeze().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_embeddings = np.concatenate(labelled_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, _ = next(iter(unlabelled_loader))\n",
    "with torch.no_grad():\n",
    "    test_embedding = embedding(test_x.cuda())['avgpool'].squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2048)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2048)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_embedding[0, :] - labelled_embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = cKDTree(labelled_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([23.39474082, 32.54301783, 24.19577934, 25.08151453, 22.563244  ,\n",
       "        49.72409988, 30.81506044, 46.88290054, 21.01325877, 45.54252688,\n",
       "        56.09761756, 22.40028562, 24.29599516, 21.12151748, 32.7471984 ,\n",
       "        44.54750342, 27.67510502, 30.30095982, 32.32567773, 22.00556638,\n",
       "        34.54423174, 44.22585938, 28.61319191, 26.84988107, 27.21627808,\n",
       "        24.95879876, 39.11878122, 34.04050599, 26.09931827, 41.60534561,\n",
       "        23.73287253, 46.31750967]),\n",
       " array([97, 97, 24, 97, 16, 37, 84, 73, 97,  1, 62, 16, 16, 16, 69, 78, 48,\n",
       "        16, 78, 16, 84, 81, 97, 16, 71, 97, 78, 39, 48, 44, 97, 23]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.query(test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2048)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=25, algorithm='ball_tree').fit(labelled_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[23.39474082, 23.92687547, 24.07994547, 24.16215359, 25.30447421,\n",
       "         25.32974056, 25.54202081, 25.57500532, 25.58128655, 25.79459596,\n",
       "         26.0983242 , 26.12695711, 26.42897969, 26.51798611, 27.03385658,\n",
       "         27.30421524, 27.40442335, 27.4128344 , 28.03571413, 28.34874346,\n",
       "         28.66374729, 28.92934196, 29.00631606, 29.50966459, 29.62208403],\n",
       "        [32.54301783, 32.75440432, 32.84976731, 33.67812429, 33.78644532,\n",
       "         33.79169097, 33.87860727, 33.95709908, 34.0361709 , 34.22118178,\n",
       "         34.57610516, 34.61810152, 34.73684023, 34.75666159, 34.90725486,\n",
       "         34.99181043, 35.03920328, 35.07434093, 35.18014141, 35.27962974,\n",
       "         35.30409027, 35.40903038, 35.46429757, 35.64657945, 35.67639633],\n",
       "        [24.19577934, 24.22186981, 24.26694746, 24.47327735, 24.69089942,\n",
       "         24.99949511, 25.10673734, 25.55406393, 25.85695949, 25.87274521,\n",
       "         26.1843401 , 26.23427321, 26.44981428, 26.60413638, 27.08665683,\n",
       "         27.12365632, 27.44429916, 27.73175233, 27.80695582, 27.82918712,\n",
       "         27.95266912, 28.15234873, 28.18368268, 28.43536245, 28.48336747],\n",
       "        [25.08151453, 26.97258041, 27.11591815, 27.28935856, 27.39400844,\n",
       "         27.8831932 , 28.17187801, 28.23756654, 28.42892882, 28.48130211,\n",
       "         28.91229382, 29.14490668, 29.45266908, 29.58089329, 29.5840055 ,\n",
       "         29.59730414, 29.60357589, 29.89382464, 30.12362636, 30.28173123,\n",
       "         30.3076261 , 30.50403336, 31.38239038, 31.73275938, 31.84526356],\n",
       "        [22.563244  , 23.40191712, 23.98818974, 24.22358891, 24.76540162,\n",
       "         25.05423762, 25.16074393, 25.45656974, 25.5278533 , 25.60286355,\n",
       "         25.67729636, 26.15844669, 26.46918011, 26.52534847, 26.7805091 ,\n",
       "         27.42341322, 27.43845539, 27.54913501, 27.72718413, 27.8065573 ,\n",
       "         27.85234393, 27.97640075, 28.35623911, 28.44239161, 28.63780797],\n",
       "        [49.72409988, 50.56341103, 50.76927075, 51.245899  , 51.38584883,\n",
       "         51.46566707, 51.93498965, 52.19001367, 52.36367485, 52.44109138,\n",
       "         52.52895908, 52.55483291, 52.56687047, 52.58578213, 52.71936726,\n",
       "         52.87940516, 53.00461824, 53.04970966, 53.07040829, 53.09080638,\n",
       "         53.28685561, 53.35041084, 53.35502281, 53.39789365, 53.45112155],\n",
       "        [30.81506044, 30.87873771, 31.92055721, 31.94614561, 32.22764652,\n",
       "         32.60795613, 32.65367499, 32.77125286, 33.09398815, 33.12607973,\n",
       "         33.23509902, 33.64190081, 33.71756744, 33.72965779, 33.85779439,\n",
       "         34.16515874, 34.16952241, 34.29956301, 34.30284891, 34.31615526,\n",
       "         34.49629316, 34.59296001, 34.64934844, 34.68871143, 34.90917831],\n",
       "        [46.88290054, 47.03109446, 49.89868546, 50.11026128, 50.18643776,\n",
       "         50.38689039, 50.45683038, 50.89596373, 50.96818724, 51.037613  ,\n",
       "         51.08903375, 51.19704337, 51.45247923, 51.45278897, 51.46567062,\n",
       "         51.52912831, 51.6003996 , 51.68333578, 51.68523249, 51.78789316,\n",
       "         51.79918531, 52.01117194, 52.04961776, 52.07303948, 52.1229562 ],\n",
       "        [21.01325877, 21.163357  , 21.70151322, 21.80171246, 22.30997145,\n",
       "         23.03522924, 23.07616701, 23.28850969, 23.459838  , 23.74463929,\n",
       "         23.8827142 , 23.95435395, 24.03853888, 24.23015528, 24.23256275,\n",
       "         24.27223031, 24.79183948, 25.43736079, 25.69623706, 26.07379689,\n",
       "         26.14874448, 26.34398708, 26.5835746 , 26.78266465, 26.80011006],\n",
       "        [45.54252688, 46.64667105, 47.12563069, 47.16390773, 47.18887597,\n",
       "         47.22553567, 47.34103547, 47.41861086, 47.43391943, 47.50532173,\n",
       "         47.67448574, 47.73829677, 47.98095473, 48.01486199, 48.02494259,\n",
       "         48.07366719, 48.20121144, 48.42769864, 48.50077063, 48.54451071,\n",
       "         48.56033407, 48.62116366, 48.65863211, 48.66499117, 48.68754359],\n",
       "        [56.09761756, 56.30920174, 56.49475604, 56.5059464 , 56.61659302,\n",
       "         56.7223965 , 56.89805832, 56.89972008, 56.96036469, 57.28247845,\n",
       "         57.31992769, 57.36428053, 57.7036665 , 57.72315   , 57.78008321,\n",
       "         57.80107769, 57.84963462, 57.85435806, 57.89439692, 57.93170923,\n",
       "         57.97758877, 58.0144496 , 58.11945752, 58.22129574, 58.24965086],\n",
       "        [22.40028562, 23.11352238, 23.67745962, 23.8852818 , 23.93092701,\n",
       "         24.75491575, 25.00930395, 25.02608555, 25.06269502, 25.21762579,\n",
       "         25.33787283, 25.85780794, 25.89756973, 26.49937786, 26.68309551,\n",
       "         26.94975175, 27.07835597, 27.39862309, 27.46514409, 27.53006115,\n",
       "         27.80754476, 27.83414373, 27.87126088, 27.97914735, 28.23085676],\n",
       "        [24.29599516, 24.42369   , 24.80110077, 25.48001311, 25.73009391,\n",
       "         25.87084421, 26.02493442, 26.14261465, 26.424653  , 26.44189527,\n",
       "         26.90692581, 26.92378156, 26.96465697, 27.1620906 , 27.21715879,\n",
       "         27.29781283, 27.33213988, 27.42306354, 27.51251657, 27.70595178,\n",
       "         27.99136213, 28.30710541, 28.73793954, 28.8450281 , 28.88379108],\n",
       "        [21.12151748, 22.21284372, 23.24103618, 23.92071984, 24.02888244,\n",
       "         24.12083766, 24.38917671, 24.8856006 , 24.9686752 , 25.20344795,\n",
       "         25.32145883, 25.32734578, 25.59375806, 25.84271199, 26.24124711,\n",
       "         26.56757396, 26.64152753, 26.89112652, 27.1135032 , 27.20118343,\n",
       "         27.36112511, 27.44616469, 27.65791051, 27.68180167, 27.98312853],\n",
       "        [32.7471984 , 32.95659334, 33.20991832, 33.23582304, 33.52465284,\n",
       "         33.62891992, 34.15675433, 34.22086736, 34.35941183, 34.3708654 ,\n",
       "         35.17546844, 35.68823357, 35.74909621, 35.78700483, 35.83323779,\n",
       "         35.84584252, 35.90590974, 35.98467262, 36.15729338, 36.23235274,\n",
       "         36.36932505, 36.511347  , 36.51452518, 36.64351563, 36.67844953],\n",
       "        [44.54750342, 45.20634151, 45.68759743, 46.4872611 , 46.59295419,\n",
       "         46.74157599, 46.82031393, 46.8208732 , 46.84019921, 46.84065336,\n",
       "         47.06526444, 47.07430519, 47.11803944, 47.19018853, 47.24419018,\n",
       "         47.29128441, 47.32990621, 47.39077489, 47.56422062, 47.58392125,\n",
       "         47.59943702, 47.66138685, 47.72051981, 47.78956066, 47.83845396],\n",
       "        [27.67510502, 29.24598695, 29.32620791, 30.20870518, 30.30685872,\n",
       "         31.01103265, 31.03519514, 31.11795316, 31.12954347, 31.14842925,\n",
       "         31.19217758, 31.26558929, 31.36932837, 31.39536017, 31.45856973,\n",
       "         31.94401803, 31.95561186, 32.0509971 , 32.14292346, 32.2630749 ,\n",
       "         32.44315235, 32.68270643, 33.09890282, 33.1639653 , 33.17180989],\n",
       "        [30.30095982, 31.29015501, 31.73475533, 32.02012986, 32.42241661,\n",
       "         32.49665781, 32.50918417, 32.55245516, 32.60329639, 32.89781487,\n",
       "         33.40992313, 33.44192202, 33.46653174, 33.52485457, 33.62200142,\n",
       "         33.64195646, 33.72572627, 34.1858642 , 34.22307229, 34.25596294,\n",
       "         34.31752733, 34.41257879, 34.89260794, 34.98856241, 35.03208196],\n",
       "        [32.32567773, 32.50147374, 32.53581636, 32.5641612 , 32.70006857,\n",
       "         32.7497436 , 33.01454504, 33.10131136, 33.34040701, 33.51609971,\n",
       "         33.84263038, 33.92253296, 34.20250985, 34.30155287, 34.31625573,\n",
       "         34.32819768, 34.38726786, 34.45643229, 34.67053089, 34.74712881,\n",
       "         34.74851513, 34.7587762 , 34.94633512, 35.31355562, 35.38529876],\n",
       "        [22.00556638, 22.70657367, 23.04058168, 23.12502332, 23.63895354,\n",
       "         23.92296144, 23.95852797, 24.21004221, 24.21083997, 24.75703054,\n",
       "         25.14502245, 25.15668298, 25.19093019, 25.2535737 , 25.85108137,\n",
       "         25.86324247, 26.03426129, 26.46057126, 26.70079866, 26.71705369,\n",
       "         27.13151623, 27.16423311, 27.27409348, 27.3852341 , 27.60301825],\n",
       "        [34.54423174, 34.88567323, 35.25949563, 35.3347633 , 35.50302085,\n",
       "         35.61579027, 35.78232465, 35.80796981, 35.99677271, 36.15834727,\n",
       "         36.19852734, 36.20801415, 36.28632576, 36.35595269, 36.61418058,\n",
       "         37.02979   , 37.05161715, 37.08194582, 37.44446045, 37.53905228,\n",
       "         37.59879118, 37.61045105, 37.79945032, 37.86258206, 37.88390893],\n",
       "        [44.22585938, 45.36878676, 45.45457208, 46.00428777, 46.08088983,\n",
       "         46.13019087, 46.2861182 , 46.30879135, 46.52568078, 46.9430674 ,\n",
       "         46.95219953, 46.97441352, 47.20557417, 47.23733104, 47.39500302,\n",
       "         47.45796928, 47.59448922, 47.87269309, 47.92074358, 47.99785446,\n",
       "         48.18540343, 48.18709734, 48.21638658, 48.28953885, 48.32038978],\n",
       "        [28.61319191, 29.18558037, 29.5056512 , 29.88734217, 30.28958827,\n",
       "         30.41829058, 30.599179  , 30.65882529, 30.87898524, 30.89967455,\n",
       "         30.9764353 , 31.251241  , 31.25245637, 31.2911855 , 31.45744061,\n",
       "         31.53104913, 31.73358214, 31.95322137, 31.98433733, 32.10189671,\n",
       "         32.41717255, 32.64612825, 32.64883446, 32.72769631, 32.73055294],\n",
       "        [26.84988107, 27.09029604, 27.27926994, 27.35286674, 27.84435011,\n",
       "         27.93966389, 28.1377915 , 28.17458531, 28.32463364, 28.48418806,\n",
       "         28.78837431, 28.80202811, 29.52753677, 29.53631415, 29.54560311,\n",
       "         29.62071384, 29.75358509, 29.94784387, 29.94970007, 29.99780138,\n",
       "         30.12921836, 30.47099035, 30.79510815, 31.06537776, 31.17014022],\n",
       "        [27.21627808, 27.62849701, 27.76404213, 27.94034946, 27.98771716,\n",
       "         28.07016585, 28.16479428, 28.31978046, 28.76448093, 28.93904454,\n",
       "         29.06277629, 29.18027645, 29.51944992, 29.56073177, 29.61925778,\n",
       "         29.62937953, 29.74867753, 29.79865125, 30.08733216, 30.34979218,\n",
       "         30.50543137, 30.53042224, 30.59440104, 30.76319963, 30.93959785],\n",
       "        [24.95879876, 26.91508027, 27.69377845, 27.76477983, 27.96693609,\n",
       "         28.12861543, 28.28374023, 28.2932596 , 28.35158628, 28.44122144,\n",
       "         28.46169741, 28.96638929, 28.98123159, 29.00058494, 29.19376266,\n",
       "         29.31621865, 29.81631531, 29.82460415, 29.91212615, 30.3271863 ,\n",
       "         30.37867592, 30.80105281, 31.49426792, 31.67204798, 31.74727923],\n",
       "        [39.11878122, 39.66114799, 40.16373305, 40.1784259 , 40.49635697,\n",
       "         40.94155876, 41.18975223, 41.22939182, 41.29578374, 41.37334753,\n",
       "         41.38283181, 41.48748902, 41.58899607, 41.59159215, 41.5939446 ,\n",
       "         41.74412167, 41.77380935, 41.80074623, 41.89954248, 41.91106271,\n",
       "         41.94669973, 41.94890869, 42.02644496, 42.15270456, 42.22563169],\n",
       "        [34.04050599, 34.4074808 , 34.42089299, 34.48482456, 34.52828286,\n",
       "         34.59185583, 34.78022677, 35.06195936, 35.10447107, 35.25246062,\n",
       "         35.32478062, 35.47648054, 35.7378302 , 35.87446738, 35.91774599,\n",
       "         35.98141303, 36.03246118, 36.06242401, 36.3295959 , 36.46470929,\n",
       "         36.59707837, 36.61699426, 36.82584585, 36.85682756, 36.97147605],\n",
       "        [26.09931827, 26.43810455, 27.46835151, 27.7305029 , 28.10821671,\n",
       "         28.72412942, 28.82876983, 29.23029289, 29.40058598, 29.61472838,\n",
       "         29.65439295, 29.74185096, 29.77522427, 29.86600672, 30.17229588,\n",
       "         30.33929062, 30.61744098, 30.64800896, 30.81531252, 30.87248674,\n",
       "         31.43375397, 31.99720074, 32.12419244, 32.16641585, 32.32107127],\n",
       "        [41.60534561, 41.61963219, 41.73773353, 42.05094193, 42.06764958,\n",
       "         42.17051956, 42.50545014, 42.74104391, 42.92942687, 43.01324789,\n",
       "         43.03691647, 43.09593909, 43.15515901, 43.19637853, 43.29433165,\n",
       "         43.34458366, 43.35626018, 43.5232063 , 43.5600209 , 43.60529949,\n",
       "         43.61596254, 43.73037323, 43.73166827, 43.80728053, 43.84542069],\n",
       "        [23.73287253, 24.28096684, 25.31197458, 25.62455039, 25.72394658,\n",
       "         25.76587877, 26.10432358, 26.66053384, 26.7792338 , 27.06940335,\n",
       "         27.24783881, 27.28918894, 27.31074781, 27.40458355, 27.63482321,\n",
       "         27.73075538, 28.06658234, 28.33281   , 28.53587362, 28.83485704,\n",
       "         28.91321083, 29.42777612, 29.50991474, 29.75814705, 29.90010803],\n",
       "        [46.31750967, 47.23327413, 47.56263877, 47.6564772 , 47.94819166,\n",
       "         48.00595583, 48.15237235, 48.32108236, 48.34751781, 48.38628479,\n",
       "         48.64848858, 48.70275183, 48.72651876, 48.99062512, 49.03996881,\n",
       "         49.11717505, 49.16804084, 49.22561052, 49.25101328, 49.30111382,\n",
       "         49.3342986 , 49.35531873, 49.41830743, 49.53846123, 49.63060746]]),\n",
       " array([[97, 89, 24, 16, 39, 35, 72, 56, 78, 22, 48, 71, 37, 46, 84, 51,\n",
       "         70, 81, 52, 42, 15, 47, 50, 79, 98],\n",
       "        [97, 47, 48, 16, 78, 56, 72, 81, 42, 24, 52, 39, 22,  3, 35, 37,\n",
       "         71, 50, 74, 14, 84, 63, 15, 46, 79],\n",
       "        [24, 72, 97, 16, 48, 22, 39, 56, 71, 35, 84, 78, 81, 52, 37, 46,\n",
       "         47, 50, 89, 43, 93,  9, 79, 42, 18],\n",
       "        [97, 16, 24, 72, 22, 78, 56, 48, 84, 71, 81, 37, 46, 42, 50, 93,\n",
       "         89, 35, 39, 54, 94, 52, 47,  5, 98],\n",
       "        [16, 97, 24, 48, 78, 46, 72, 84, 22, 81, 39, 56, 42, 52, 71, 93,\n",
       "         18, 37, 35, 50, 89, 14, 15, 47, 98],\n",
       "        [37, 78, 14, 25, 39, 47, 18, 15,  5,  2,  6, 80, 63, 29, 84, 99,\n",
       "         88, 77, 48, 70, 42, 81, 24, 16, 92],\n",
       "        [84, 97, 37, 78, 16, 81, 39, 50, 24, 48, 71, 72, 47, 56, 22, 42,\n",
       "         14, 46,  3, 15, 74, 35, 70, 98,  5],\n",
       "        [73,  4, 37, 13, 15, 89, 35, 32, 78, 16, 61, 24, 55, 51, 96, 42,\n",
       "         25, 46, 49, 70,  3,  5, 71, 84, 52],\n",
       "        [97, 16, 78, 72, 24, 39, 93, 48, 14, 46, 22, 52, 84, 81, 35, 56,\n",
       "         71, 37, 89, 47, 42, 50, 15, 98, 70],\n",
       "        [ 1, 78, 48, 24, 62, 25, 74, 52, 61, 37, 47, 22, 56, 50, 39, 71,\n",
       "         42, 16, 27, 69, 81, 84, 35, 49, 15],\n",
       "        [62, 43, 24, 39,  3, 98, 52, 58, 75,  9, 37, 46, 35, 15, 80, 78,\n",
       "         79, 51, 63, 96, 40, 12, 56, 48, 74],\n",
       "        [16, 97, 81, 39, 24, 71, 22, 78, 72, 48, 84, 46, 56, 89, 37, 52,\n",
       "         35, 50, 47, 42, 14,  5, 93, 51, 18],\n",
       "        [16, 24, 97, 48, 81, 72, 78, 43, 22, 42, 84, 35, 71, 56, 37, 14,\n",
       "         39, 89, 46, 52, 15, 63, 79, 93,  9],\n",
       "        [16, 97, 72, 84, 48, 24, 81, 22, 35, 89, 56, 78, 71, 46, 39, 52,\n",
       "         15, 79, 42, 47, 70, 14, 37, 50, 63],\n",
       "        [69, 16, 78, 55, 24, 48, 81, 84, 97, 46, 39, 42, 50, 89, 52, 13,\n",
       "         18, 74, 71,  5, 47, 72, 51, 56, 22],\n",
       "        [78, 37, 47, 50, 52, 63, 39, 48, 93, 18, 29, 71, 44, 62,  5, 24,\n",
       "         42, 14, 22, 84, 56, 98, 88, 97, 77],\n",
       "        [48, 84, 24, 97, 47, 50, 16, 56, 39, 22, 72, 78, 81, 71, 37, 52,\n",
       "         79, 42, 46, 35,  9, 14, 63, 18, 98],\n",
       "        [16, 15, 81, 52, 35, 97, 48, 56, 24, 39, 84, 51, 22, 72, 78,  5,\n",
       "         79, 71, 98, 46, 93, 37, 50, 42, 70],\n",
       "        [78, 24, 89, 22, 97, 48, 16, 46, 84, 37, 35, 72, 49, 39, 17, 42,\n",
       "         15, 56, 81, 14, 52, 98, 51, 71, 47],\n",
       "        [16, 97, 24, 72, 56, 22, 71, 48, 78, 81, 42, 39, 35, 89, 84, 46,\n",
       "         37, 47, 93, 52, 79, 18, 49, 50, 63],\n",
       "        [84, 78, 55, 97, 24, 81, 88, 48, 52, 16, 80, 37, 46, 49, 42, 39,\n",
       "         56, 72, 22, 14, 71, 47, 63, 20,  1],\n",
       "        [81, 39, 51, 52, 82, 16, 24, 48, 15, 46, 40, 18, 49, 35, 78, 22,\n",
       "          5, 37, 72, 71, 97, 79, 69, 43, 12],\n",
       "        [97, 78, 22, 24, 48, 84, 16, 39, 81, 37, 71, 14, 70,  5, 72, 46,\n",
       "         56, 52, 42, 50, 89, 35, 93, 47, 77],\n",
       "        [16, 48, 97, 24, 39, 35, 72, 56, 15, 22, 78, 84, 71, 89, 98, 46,\n",
       "         52, 81, 63, 49, 37, 42, 18, 79,  5],\n",
       "        [71, 84, 48, 50, 97, 78, 16, 37, 81, 56, 24, 22, 72, 46, 52, 39,\n",
       "         93, 74, 18, 42, 35, 79, 89, 14, 55],\n",
       "        [97, 51, 16, 24, 84, 46, 48, 22, 70, 39, 71, 72, 81, 78, 37, 56,\n",
       "         89, 35, 52,  5, 42,  2, 14, 50, 93],\n",
       "        [78, 48, 15,  0, 73, 24, 56, 70, 17, 37, 46, 52, 89, 58,  5, 51,\n",
       "         47, 42, 16, 14, 97, 39, 22, 35, 43],\n",
       "        [39, 70, 37, 81, 97, 78, 69, 22,  2, 84, 16, 48, 14, 24, 56, 46,\n",
       "         15, 42, 52, 49, 35, 72, 71,  5, 51],\n",
       "        [48, 24, 89, 56, 78, 16, 97, 42, 47, 46, 39, 72, 22, 35, 71, 81,\n",
       "         84, 15, 13, 37, 18, 52, 70, 43, 61],\n",
       "        [44, 78, 39, 71, 24, 79, 52, 42, 72, 50, 98, 84, 56, 22, 16, 18,\n",
       "          1, 62, 37, 97,  5, 48, 14, 77, 47],\n",
       "        [97, 16, 24, 78, 48, 89, 84, 72, 39, 71, 22, 46, 56, 81, 37, 52,\n",
       "         70, 35, 42, 79, 93, 47, 50, 15, 13],\n",
       "        [23, 81, 78,  5, 99, 84, 69, 39, 18, 45, 52, 47, 50, 49, 97, 90,\n",
       "         37, 14, 42, 92, 16, 35, 79, 46, 56]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbrs.kneighbors(test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
